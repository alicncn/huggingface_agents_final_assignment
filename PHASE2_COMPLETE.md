# Phase 2 - Information Retrieval Tools

## âœ… Completed Tasks

### 1. Web Search Integration
- âœ… Integrated **Tavily API** for web search
- âœ… Created `web_search` tool for general web queries
- âœ… Created `web_search_wikipedia` tool for Wikipedia-specific searches
- âœ… Support for answer generation and multiple results

### 2. Document/URL Processing
- âœ… Created `read_url` tool to extract content from any webpage
- âœ… Created `extract_links` tool to get all links from a page
- âœ… Created `search_in_document` tool to find specific text with context
- âœ… Robust error handling for network issues and malformed pages

### 3. Dependencies
- âœ… Installed `tavily-python==0.5.0` for web search
- âœ… Installed `beautifulsoup4==4.12.3` for HTML parsing
- âœ… Installed `requests==2.32.3` for HTTP requests
- âœ… Installed `lxml` and `html5lib` for better HTML parsing

## ğŸ› ï¸ Tools Added (5 Total)

### 1. `web_search(query, max_results=5)`
**Purpose:** Search the web using Tavily API  
**Example:** "Search for Mercedes Sosa discography"  
**Returns:** AI-generated answer + search results with titles, URLs, and snippets

### 2. `web_search_wikipedia(query, year=None)`
**Purpose:** Search Wikipedia specifically  
**Example:** "Search Wikipedia for Mercedes Sosa in 2022"  
**Returns:** Wikipedia-focused search results

### 3. `read_url(url, extract_text_only=True)`
**Purpose:** Read and extract content from any URL  
**Example:** "Read https://en.wikipedia.org/wiki/Mercedes_Sosa"  
**Returns:** Clean text content from the webpage (up to 10,000 chars)

### 4. `extract_links(url, filter_text=None)`
**Purpose:** Extract all links from a webpage  
**Example:** "Get all links from https://example.com"  
**Returns:** List of links with their text and URLs (up to 50 links)

### 5. `search_in_document(url, search_term, context_chars=200)`
**Purpose:** Find specific text in a webpage with surrounding context  
**Example:** "Search for 'award number' in https://example.com/paper.html"  
**Returns:** All occurrences with context before and after

## ğŸ”‘ Configuration Required

### Tavily API Key (Required for Web Search)

1. **Get a free API key:**
   - Visit: https://tavily.com
   - Sign up for a free account
   - Copy your API key

2. **Add to `.env` file:**
   ```
   TAVILY_API_KEY=tvly-your_actual_key_here
   ```

3. **Verify setup:**
   ```bash
   python verify_phase2.py
   ```

## ğŸ“Š Challenge Prompts Now Solvable

With Phase 2 tools, the agent can now solve:

### âœ… Prompt 1: Mercedes Sosa Albums
**Task:** Count albums released between 1990-2000  
**Solution Path:**
1. `web_search_wikipedia("Mercedes Sosa discography", 2022)`
2. `read_url(wikipedia_url)`
3. Parse content to find albums in date range

### âœ… Prompt 5: Wikipedia Nominator
**Task:** Find who nominated an article for featured status  
**Solution Path:**
1. `web_search("Wikipedia featured article nomination [article name]")`
2. `read_url(nomination_page)`
3. `search_in_document(url, "nominated by")`

### âœ… Prompt 8: Veterinarian Surname
**Task:** Find veterinarian name in online textbook  
**Solution Path:**
1. `web_search("veterinary textbook [title]")`
2. `read_url(textbook_chapter_url)`
3. Extract surname from content

### âœ… Prompt 15: NASA Award Number
**Task:** Multi-step research from news to paper  
**Solution Path:**
1. `web_search("NASA exoplanet discovery news")`
2. `extract_links(news_url, "research paper")`
3. `read_url(paper_url)`
4. `search_in_document(paper_url, "award number")`

### âœ… Prompt 16: Specimen Deposition
**Task:** Find specimen location in scientific paper  
**Solution Path:**
1. `web_search("[paper title] specimen")`
2. `read_url(paper_url)`
3. `search_in_document(paper_url, "deposited")`

## ğŸ§ª Testing Phase 2

### Quick Tests (No API Key Required)
```bash
python main.py
```

Try these prompts:
1. "Read the content from https://example.com"
2. "Extract all links from https://news.ycombinator.com"
3. "Search for the word 'domain' in https://example.com"

### Full Tests (Requires Tavily API Key)
```bash
python main.py
```

Try these prompts:
1. "Search the web for information about Python programming"
2. "Search Wikipedia for information about AI"
3. "Find and read the Wikipedia article about Mercedes Sosa"

### View Example Prompts
```bash
python examples_phase2.py
```

## ğŸ—ï¸ How It Works

### Tool Registration
```python
# tools/registry.py
from tools.web_search import web_search, web_search_wikipedia
from tools.document_reader import read_url, extract_links, search_in_document

tools = [
    web_search,
    web_search_wikipedia,
    read_url,
    extract_links,
    search_in_document,
]
```

### Agent Decision Flow
```
User: "Find Mercedes Sosa albums from 1990-2000"
  â†“
Agent: Decides to use web_search_wikipedia
  â†“
Tool: Returns Wikipedia search results
  â†“
Agent: Decides to use read_url on Wikipedia link
  â†“
Tool: Returns full article content
  â†“
Agent: Analyzes content and counts albums
  â†“
Response: "Mercedes Sosa released X albums between 1990-2000"
```

## ğŸ”„ Multi-Step Reasoning Example

**Prompt:** "Find the NASA award number in the exoplanet discovery paper"

**Agent's Plan:**
1. ğŸ” `web_search("NASA exoplanet discovery")` â†’ Get news article
2. ğŸ“„ `read_url(news_article_url)` â†’ Read article
3. ğŸ”— `extract_links(news_url, "paper")` â†’ Find paper link
4. ğŸ“„ `read_url(paper_url)` â†’ Read paper
5. ğŸ” `search_in_document(paper_url, "award")` â†’ Find award number
6. âœ… Extract and return the award number

## âš™ï¸ Technical Details

### Error Handling
- Network timeouts (10 seconds)
- Invalid URLs
- Missing API keys
- Malformed HTML
- Content size limits (10,000 chars for read_url)

### Content Processing
- Removes script, style, nav, footer, header tags
- Cleans excessive whitespace
- Makes relative URLs absolute
- Limits output to prevent token overflow

### Search Features
- AI-generated quick answers (Tavily)
- Multiple result sources
- Relevance-ranked results
- Content snippets included

## ğŸ“ˆ Metrics

- **Tools Added:** 5
- **Dependencies Added:** 4
- **Challenge Prompts Solvable:** 5 (Prompts 1, 5, 8, 15, 16)
- **Lines of Code:** ~300

## â­ï¸ Next Phase

**Phase 3: Multimedia Analysis Tools**
- Audio transcription (Whisper)
- Video analysis (frame extraction + vision)
- Image recognition (Gemini Vision)
- Support for prompts 2, 4, 7, 11, 14

## ğŸ› Troubleshooting

### "TAVILY_API_KEY not found"
- Add your Tavily API key to `.env` file
- Get a free key at https://tavily.com

### "Request timed out"
- Check your internet connection
- The timeout is set to 10 seconds
- Some websites may block automated requests

### "No results found"
- Try a different search query
- Some searches may return no results
- Verify the URL is accessible

### "Content truncated"
- This is normal for large pages
- The tool limits content to 10,000 characters
- Use `search_in_document` to find specific text

## ğŸ“š Resources

- Tavily API Docs: https://docs.tavily.com
- BeautifulSoup Docs: https://www.crummy.com/software/BeautifulSoup/
- Requests Docs: https://requests.readthedocs.io
